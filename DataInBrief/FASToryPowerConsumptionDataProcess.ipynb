{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./StaticCaseData/FASToryPowerConsumptionData_UnProcessed.csv\"\n",
    "df= pd.read_csv(file_name)\n",
    "#data summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Data processing includes\n",
    "1. Data Normalization, these values used by neural network during learning\n",
    "    1. \"Normalized Power and Load\" contains normalized values using default sklearn MinMaxScaler parameters\n",
    "2. Labeling data, based on observation and data visualization belt tensions were classified into 3 classes.\n",
    "3. Translating load combinations to number of pallets residing on main conveyor belt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translating load combinations to number of pallets residing on main conveyor belt \n",
    "choices=[0,1,1,1,1,\n",
    "         2,2,2,2,2,2,\n",
    "         3,3,3,3,\n",
    "        4]\n",
    "conditions= [\n",
    "            df['Load Combinations'].eq(0),\n",
    "            df['Load Combinations'].eq(1),df['Load Combinations'].eq(2),df['Load Combinations'].eq(4),df['Load Combinations'].eq(8),\n",
    "\n",
    "            df['Load Combinations'].eq(3),df['Load Combinations'].eq(5),df['Load Combinations'].eq(6),df['Load Combinations'].eq(9),\n",
    "            df['Load Combinations'].eq(10),df['Load Combinations'].eq(12),\n",
    "\n",
    "            df['Load Combinations'].eq(7),df['Load Combinations'].eq(11),\n",
    "            df['Load Combinations'].eq(13),df['Load Combinations'].eq(14),\n",
    "    \n",
    "            df['Load Combinations'].eq(15)\n",
    "            ]\n",
    "df['Load'] = np.select(conditions, choices, default= df['Load Combinations'])\n",
    "\n",
    "df.to_csv(file_name.split('_')[0]+\"_Processed.csv\",index=False)\n",
    "df= pd.read_csv(file_name.split('_')[0]+\"_Processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Labeling\n",
    "\n",
    "This data is collected for conveyor belt tension ranging from 0% to 95%, there are 9 different belt tensions values in this range. \n",
    "\n",
    "| Belt Tension Class | %Belt Tension | Description|\n",
    "|:--------------------|:-------------|:------------|\n",
    "|1 | 0 | Not Useful\n",
    "|1 | 15 | Not Useful\n",
    "|1 | 30 | Not Useful\n",
    "|1 | 45 | Not Useful\n",
    "|1 | 60 | Not Useful\n",
    "|1 | 70 | Not Useful\n",
    "|2 | 75 | Moderate Useful\n",
    "|2 | 85 | Useful (Optimal)\n",
    "|3 | 95 | Over Tense\n",
    "\n",
    "Based on observation and data analysis of data collected during static and dynamic case,this data set is devided into 3 different belt tension classes which are lsited below:\n",
    "\n",
    "| Class | Belt tension values in % | Description|\n",
    "|:--------------------|:-------------|:------------|\n",
    "|1 | 0% to 70% | Not useful (low)\n",
    "|2 | 75% to 85% | Useful (optimal)\n",
    "|3 | Belt tension > 90% | Not useful (over-tense) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices=[1,1,1,1,1,1,2,2,3]\n",
    "conditions= [\n",
    "            df['%Belt Tension'].eq(0),df['%Belt Tension'].eq(15),df['%Belt Tension'].eq(30),\n",
    "            df['%Belt Tension'].eq(45),df['%Belt Tension'].eq(60),df['%Belt Tension'].eq(70),\n",
    "            df['%Belt Tension'].eq(75),df['%Belt Tension'].eq(85),df['%Belt Tension'].eq(95)\n",
    "            ]\n",
    "df['Class3'] = np.select(conditions, choices, default= df['%Belt Tension'])\n",
    "\n",
    "df.to_csv(file_name.split('_')[0]+\"_Processed.csv\",index=False)\n",
    "df= pd.read_csv(file_name.split('_')[0]+\"_Processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Scalar for real-time usage\n",
    "import joblib\n",
    "scalar_obj_path='ScalerObjects/'\n",
    "scaler_filename =[ \"Power-scaler.save\",\"pallet-scaler.save\"]\n",
    "data_frame = [ df[['Power (W)']],df[['Load Combinations']],df[['Power (W)']] ]\n",
    "for data,name in zip(data_frame,scaler_filename): \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(data)\n",
    "        print(scaler.data_max_,scaler.data_min_)\n",
    "        joblib.dump(scaler, f'./ScalerObjects/{name}') \n",
    "        df['Normalized_Power']=np.round(scaler.fit_transform(df[['Power (W)']]),3)\n",
    "        df['Normalized_Load']=np.round(scaler.fit_transform(df[['Load Combinations']]),3)\n",
    "        \n",
    "\n",
    "df.to_csv(file_name.split('_')[0]+\"_Processed.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ada090cd8529fd0de4816406a0de9b9e930c00d0fdd97b856677e032a1cd3a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('FASToryData': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
